{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandoc\n",
    "import time \n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import norm \n",
    "\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalF(x): \n",
    "\n",
    "    F = np.zeros(2)\n",
    "    \n",
    "    F[0] = 3*x[0]**2 - x[1]**2\n",
    "    F[1] = 3*x[0]*x[1]**2 - x[0]**3 - 1\n",
    "    return F\n",
    "\n",
    "def evalJ(x): \n",
    "\n",
    "    \n",
    "    J = np.array([[6*x[0], -2*x[1]], \n",
    "        [3*x[1]**2 - 3*x[0]**2, 6*x[0]*x[1]]])\n",
    "    return J\n",
    "\n",
    "def Newton(x0,tol,Nmax):\n",
    "\n",
    "    ''' inputs: x0 = initial guess, tol = tolerance, Nmax = max its'''\n",
    "    ''' Outputs: xstar= approx root, ier = error message, its = num its'''\n",
    "\n",
    "    for its in range(Nmax):\n",
    "       J = evalJ(x0)\n",
    "       Jinv = inv(J)\n",
    "       F = evalF(x0)\n",
    "       \n",
    "       x1 = x0 - Jinv.dot(F)\n",
    "       \n",
    "       if (norm(x1-x0) < tol):\n",
    "           xstar = x1\n",
    "           ier =0\n",
    "           return[xstar, ier, its]\n",
    "           \n",
    "       x0 = x1\n",
    "    \n",
    "    xstar = x1\n",
    "    ier = 1\n",
    "    return[xstar,ier,its]\n",
    "\n",
    "def lazyNewton(x0, tol, nMax):\n",
    "\n",
    "    ''' inputs: x0 = initial guess, tol = tolerance, Nmax = max its'''\n",
    "    ''' Outputs: xstar= approx root, ier = error message, its = num its'''\n",
    "\n",
    "    J = evalJ(x0)\n",
    "    Jinv = inv(J)\n",
    "\n",
    "    for its in range(nMax):\n",
    "       F = evalF(x0)\n",
    "       \n",
    "       x1 = x0 - Jinv.dot(F)\n",
    "       \n",
    "       if (norm(x1-x0) < tol):\n",
    "           xstar = x1\n",
    "           ier =0\n",
    "           return[xstar, ier, its]\n",
    "           \n",
    "       x0 = x1\n",
    "    \n",
    "    xstar = x1\n",
    "    ier = 1\n",
    "    return[xstar,ier,its]\n",
    "\n",
    "def Broyden(x0,tol,Nmax):\n",
    "\n",
    "    A0 = evalJ(x0)\n",
    "\n",
    "    v = evalF(x0)\n",
    "    A = np.linalg.inv(A0)\n",
    "\n",
    "    s = -A.dot(v)\n",
    "    xk = x0+s\n",
    "    for  its in range(Nmax):\n",
    "       w = v\n",
    "       v = evalF(xk)\n",
    "       y = v-w;                   \n",
    "       z = -A.dot(y)\n",
    "       p = -np.dot(s,z)                 \n",
    "       u = np.dot(s,A) \n",
    "       tmp = s+z\n",
    "       tmp2 = np.outer(tmp,u)\n",
    "       A = A+1./p*tmp2\n",
    "       s = -A.dot(v)\n",
    "       xk = xk+s\n",
    "       if (norm(s)<tol):\n",
    "          alpha = xk\n",
    "          ier = 0\n",
    "          return[alpha,ier,its]\n",
    "    alpha = xk\n",
    "    ier = 1\n",
    "    return[alpha,ier,its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using intitals guess x = 1 y = 1 and tolerance = 10^(-10)\n",
      "\tUsing Newton, x= 0.5 y= 0.8660254037844386\n",
      "\tAnd the method converged in 5 iterations.\n",
      "\n",
      "\tUsing Lazy Newton, x= 0.500000000040521 y= 0.8660254038535676\n",
      "\tAnd the method converged in 33 iterations.\n",
      "\n",
      "\tUsing Broydan, x= 0.5 y= 0.8660254037844387\n",
      "\tAnd the method converged in 8 iterations.\n",
      "\n",
      "Using intitals guess x = 1 y = -1 and tolerance = 10^(-10)\n",
      "\tUsing Newton, x= 0.5 y= -0.8660254037844386\n",
      "\tAnd the method converged in 5 iterations.\n",
      "\n",
      "\tUsing Lazy Newton, x= 0.500000000040521 y= -0.8660254038535676\n",
      "\tAnd the method converged in 33 iterations.\n",
      "\n",
      "\tUsing Broydan, x= 0.5 y= -0.8660254037844387\n",
      "\tAnd the method converged in 8 iterations.\n",
      "\n",
      "Using intitals guess x = 0 y = 0 and tolerance = 10^(-10)\n",
      "\tUsing Newton\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[207], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing intitals guess x =\u001b[39m\u001b[38;5;124m\"\u001b[39m, x0[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my =\u001b[39m\u001b[38;5;124m\"\u001b[39m, x0[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand tolerance = 10^(-10)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mUsing Newton\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m [xstar,ier,its] \u001b[38;5;241m=\u001b[39m \u001b[43mNewton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnMax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAnd the method converged in\u001b[39m\u001b[38;5;124m\"\u001b[39m, its, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[206], line 23\u001b[0m, in \u001b[0;36mNewton\u001b[1;34m(x0, tol, Nmax)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m its \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Nmax):\n\u001b[0;32m     22\u001b[0m    J \u001b[38;5;241m=\u001b[39m evalJ(x0)\n\u001b[1;32m---> 23\u001b[0m    Jinv \u001b[38;5;241m=\u001b[39m \u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m    F \u001b[38;5;241m=\u001b[39m evalF(x0)\n\u001b[0;32m     26\u001b[0m    x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m-\u001b[39m Jinv\u001b[38;5;241m.\u001b[39mdot(F)\n",
      "File \u001b[1;32mc:\\Users\\maddr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\maddr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1,1]);\n",
    "tol = 1e-10\n",
    "nMax = 10000\n",
    "\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1], \"and tolerance = 10^(-10)\")\n",
    "\n",
    "[xstar,ier,its] = Newton(x0, tol, nMax)\n",
    "print(\"\\tUsing Newton, x=\",xstar[0],\"y=\",xstar[1])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "[xstar,ier,its] = lazyNewton(x0, tol, nMax)\n",
    "print(\"\\tUsing Lazy Newton, x=\",xstar[0],\"y=\",xstar[1])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "[xstar,ier,its] = Broyden(x0,tol,nMax)\n",
    "print(\"\\tUsing Broydan, x=\",xstar[0],\"y=\",xstar[1])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "x0 = np.array([1, -1])\n",
    "\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1], \"and tolerance = 10^(-10)\")\n",
    "\n",
    "[xstar,ier,its] = Newton(x0, tol, nMax)\n",
    "print(\"\\tUsing Newton, x=\",xstar[0],\"y=\",xstar[1])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "[xstar,ier,its] = lazyNewton(x0, tol, nMax)\n",
    "print(\"\\tUsing Lazy Newton, x=\",xstar[0],\"y=\",xstar[1])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "[xstar,ier,its] = Broyden(x0,tol,nMax)\n",
    "print(\"\\tUsing Broydan, x=\",xstar[0],\"y=\",xstar[1])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "\n",
    "x0 = np.array([0,0])\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1], \"and tolerance = 10^(-10)\")\n",
    "\n",
    "print(\"\\tUsing Newton\")\n",
    "[xstar,ier,its] = Newton(x0, tol, nMax)\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalF(x):\n",
    "\n",
    "    F = np.zeros(3)\n",
    "    F[0] = x[0] +math.cos(x[0]*x[1]*x[2])-1.\n",
    "    F[1] = (1.-x[0])**(0.25) + x[1] +0.05*x[2]**2 -0.15*x[2]-1\n",
    "    F[2] = -x[0]**2-0.1*x[1]**2 +0.01*x[1]+x[2] -1\n",
    "    return F\n",
    "\n",
    "def evalJ(x): \n",
    "\n",
    "    J =np.array([[1.+x[1]*x[2]*math.sin(x[0]*x[1]*x[2]),x[0]*x[2]*math.sin(x[0]*x[1]*x[2]),x[1]*x[0]*math.sin(x[0]*x[1]*x[2])],\n",
    "          [-0.25*(1-x[0])**(-0.75),1,0.1*x[2]-0.15],\n",
    "          [-2*x[0],-0.2*x[1]+0.01,1]])\n",
    "    return J\n",
    "\n",
    "def Newton(x0,tol,Nmax):\n",
    "\n",
    "    ''' inputs: x0 = initial guess, tol = tolerance, Nmax = max its'''\n",
    "    ''' Outputs: xstar= approx root, ier = error message, its = num its'''\n",
    "\n",
    "    for its in range(Nmax):\n",
    "       J = evalJ(x0)\n",
    "       Jinv = inv(J)\n",
    "       F = evalF(x0)\n",
    "       \n",
    "       x1 = x0 - Jinv.dot(F)\n",
    "       \n",
    "       if (norm(x1-x0) < tol):\n",
    "           xstar = x1\n",
    "           ier =0\n",
    "           return[xstar, ier, its]\n",
    "           \n",
    "       x0 = x1\n",
    "    \n",
    "    xstar = x1\n",
    "    ier = 1\n",
    "    return[xstar,ier,its]\n",
    "\n",
    "\n",
    "def evalg(x):\n",
    "\n",
    "    F = evalF(x)\n",
    "    g = F[0]**2 + F[1]**2 + F[2]**2\n",
    "    return g\n",
    "\n",
    "def eval_gradg(x):\n",
    "    F = evalF(x)\n",
    "    J = evalJ(x)\n",
    "    \n",
    "    gradg = np.transpose(J).dot(F)\n",
    "    return gradg\n",
    "\n",
    "\n",
    "###############################\n",
    "### steepest descent code\n",
    "\n",
    "def SteepestDescent(x,tol,Nmax):\n",
    "    \n",
    "    for its in range(Nmax):\n",
    "        g1 = evalg(x)\n",
    "        z = eval_gradg(x)\n",
    "        z0 = norm(z)\n",
    "\n",
    "        if z0 == 0:\n",
    "            print(\"zero gradient\")\n",
    "        z = z/z0\n",
    "        alpha1 = 0\n",
    "        alpha3 = 1\n",
    "        dif_vec = x - alpha3*z\n",
    "        g3 = evalg(dif_vec)\n",
    "\n",
    "        while g3>=g1:\n",
    "            alpha3 = alpha3/2\n",
    "            dif_vec = x - alpha3*z\n",
    "            g3 = evalg(dif_vec)\n",
    "            \n",
    "        if alpha3<tol:\n",
    "            # print(\"no likely improvement\")\n",
    "            ier = 0\n",
    "            return [x,g1,ier]\n",
    "        \n",
    "        alpha2 = alpha3/2\n",
    "        dif_vec = x - alpha2*z\n",
    "        g2 = evalg(dif_vec)\n",
    "\n",
    "        h1 = (g2 - g1)/alpha2\n",
    "        h2 = (g3-g2)/(alpha3-alpha2)\n",
    "        h3 = (h2-h1)/alpha3\n",
    "\n",
    "        alpha0 = 0.5*(alpha2 - h1/h3)\n",
    "        dif_vec = x - alpha0*z\n",
    "        g0 = evalg(dif_vec)\n",
    "\n",
    "        if g0<=g3:\n",
    "            alpha = alpha0\n",
    "            gval = g0\n",
    "\n",
    "        else:\n",
    "            alpha = alpha3\n",
    "            gval =g3\n",
    "\n",
    "        x = x - alpha*z\n",
    "\n",
    "        if abs(gval - g1)<tol:\n",
    "            ier = 0\n",
    "            return [x,gval,ier]\n",
    "\n",
    "    print('max iterations exceeded')    \n",
    "    ier = 1        \n",
    "    return [x,g1,ier]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using intitals guess x = 0.0 y = 1.5 z = 7.0 and tolerance = 10^(-10)\n",
      "\tUsing Newton, x= 0.0 y= 0.10000000000000014 z= 1.0\n",
      "\tAnd the method converged in 5 iterations.\n",
      "\n",
      "Using intitals guess x = 0.0 y = 1.5 z = 7.0 and tolerance = 10^(-10)\n",
      "\tUsing Steepest Descent, x= -7.765830214218307e-05 y= 0.09998043310291442 z= 0.9999811843376458\n",
      "\tAnd the method converged in 5 iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([0, 1.5, 7])\n",
    "tol = 1e-6\n",
    "\n",
    "nMax = 1000\n",
    "\n",
    "[xstar,ier,its] = Newton(x0, tol, nMax)\n",
    "\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1],\"z =\", x0[2], \"and tolerance = 10^(-10)\")\n",
    "print(\"\\tUsing Newton, x=\",xstar[0],\"y=\",xstar[1],\"z=\",xstar[2])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "\n",
    "[xstar,gval,ier] = SteepestDescent(x0, tol, nMax)\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1],\"z =\", x0[2], \"and tolerance = 10^(-10)\")\n",
    "print(\"\\tUsing Steepest Descent, x=\",xstar[0],\"y=\",xstar[1],\"z=\",xstar[2])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using intitals guess x = 0.0 y = 1.5 z = 7.0 and tolerance = 10^(-10)\n",
      "\tUsing Steepest Descent, x= -0.030618240374105044 y= 0.10462095623872017 z= 1.0103395751576336\n",
      "\tAnd the method converged in 5 iterations.\n",
      "\n",
      "Using intitals guess x = -0.030618240374105044 y = 0.10462095623872017 z = 1.0103395751576336 and tolerance = 10^(-10)\n",
      "\tUsing Newton, x= 1.6309057981452046e-05 y= 0.09987836323708689 z= 0.9990580605401616\n",
      "\tAnd the method converged in 0 iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([0, 1.5, 7])\n",
    "tol = 5e-2\n",
    "nMax = 1000\n",
    "\n",
    "[xstar,gval,ier] = SteepestDescent(x0, tol, nMax)\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1],\"z =\", x0[2], \"and tolerance = 10^(-10)\")\n",
    "print(\"\\tUsing Steepest Descent, x=\",xstar[0],\"y=\",xstar[1],\"z=\",xstar[2])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")\n",
    "\n",
    "x0 = xstar\n",
    "[xstar,ier,its] = Newton(x0, tol, nMax)\n",
    "print(\"Using intitals guess x =\", x0[0],\"y =\", x0[1],\"z =\", x0[2], \"and tolerance = 10^(-10)\")\n",
    "print(\"\\tUsing Newton, x=\",xstar[0],\"y=\",xstar[1],\"z=\",xstar[2])\n",
    "print(\"\\tAnd the method converged in\", its, \"iterations.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
